### **TASK: AL-22**

#### **Title:**
Prompt Architecture: Implement Dynamic Persona and Robust Dialogue Management

#### **Context:**
Our current prompts are too rigid and do not fully leverage the conversational capabilities of the AI or the flavor of our personas. This task is to re-architect our key prompt templates for the `plan_task` tool to be more dynamic and robust. We will instruct the AI to manage the dialogue flow (ensuring all its questions are answered) and to embody its persona in a non-repetitive, engaging way. This will transform the user experience from a simple command-response sequence into a genuine collaboration with a specialist AI co-worker.

#### **Implementation Details:**

1.  **Refactor `review_context.md` for Dialogue Management:**
    *   The core change will be in the `review_context.md` prompt. We will add a new directive instructing the AI on how to handle partial or incomplete answers from the human developer.
    *   The prompt will now instruct the AI to maintain a "checklist" of its own questions in its internal context. After receiving a human response, it must check which questions have been answered and which have not.
    *   If questions remain, the AI will be directed to re-prompt the user, asking only for the remaining information.
    *   It will only call `alfred.provide_review` once **all** questions have been answered.

2.  **Refactor All Prompts for Persona Integration:**
    *   Every prompt template will be updated to include a "Persona Guidelines" section.
    *   This section will explicitly instruct the AI to **not** use canned phrases but to **embody the persona's character** throughout the conversation.
    *   We will provide examples of tone and style, but the final wording will be left to the AI's discretion, encouraging variability.
    *   The `persona.yml` files will be updated with new fields like `greeting` and `communication_style` to provide richer context for the AI.

**Dev Notes:**
*   This is a pure prompt engineering task. The underlying tool logic (`submit_work`, `provide_review`) does not need to change. The State Machine remains the same.
*   We are shifting more responsibility for dialogue management onto the "Smart Client" AI, which is perfectly aligned with our architecture. Our "Dumb Orchestrator" simply waits until the `provide_review` tool is called with a complete set of clarifications.

**Files to Modify/Create:**

1.  **`src/alfred/personas/planning.yml` (MODIFY):**
    ```yaml
    name: "Alex"
    title: "Solution Architect"
    # ... other fields ...
    
    # --- NEW FIELDS ---
    greeting: "Hey there! I'm Alex. I'll be your solution architect for this task. My job is to help you create a rock-solid technical plan before we write any code. Let's get the ball rolling."
    
    communication_style: "Professional yet approachable. I explain complex technical concepts in simple terms. I am proactive in identifying risks and dependencies. I focus on the 'why' behind the architecture, not just the 'what'."
    
    thinking_methodology:
      - "Always start with the business goal and work backwards to the technical solution."
      - "Favor simplicity and clarity over unnecessary complexity."
      - "Ensure every part of the plan is testable and verifiable."
    ```

2.  **`src/alfred/templates/prompts/plan_task/contextualize.md` (MODIFY):**
    ```markdown
    # ROLE: {{ persona.name }}, {{ persona.title }}
    # ...

    ---
    ### **Persona Guidelines**

    **Your Persona:** {{ persona.name }}, {{ persona.title }}.
    **Communication Style:** {{ persona.communication_style }}

    You MUST embody this persona. **Do not use repetitive, canned phrases.** Your first message to the user should be a unique greeting based on the persona's `greeting` and `style`. For example: `{{ persona.greeting }}`. Adapt your language to feel like a genuine, collaborative partner.
    ---

    **Task Context:**
    ...
    ```

3.  **`src/alfred/templates/prompts/plan_task/review_context.md` (REPLACE):**
    ```markdown
    # ROLE: {{ persona.name }}, {{ persona.title }}
    # ...
    # STATE: review_context

    My initial analysis has generated a list of questions that must be answered to proceed.

    ---
    ### **Persona Guidelines**

    **Your Persona:** {{ persona.name }}, {{ persona.title }}.
    **Communication Style:** {{ persona.communication_style }}

    You are now in a **Clarification Loop**. Your goal is to get complete answers for all your questions from the human developer.
    ---
    ### **Directive: Manage Clarification Dialogue**

    1.  **Maintain a checklist** of the questions below in your context.
    2.  **Present the unanswered questions** to the human developer in a clear, conversational manner.
    3.  **Receive their response.** They may not answer all questions at once.
    4.  **Check your list.** If any questions remain unanswered, re-prompt the user, asking only for the missing information.
    5.  **Repeat until all questions are answered.**

    **My Questions Checklist:**
    {% set artifact = artifact_content | fromjson %}
    {% for question in artifact.questions_for_developer %}
    - [ ] {{ question }}
    {% endfor %}

    ---
    ### **Required Action**

    **ONLY when all questions have been answered**, you MUST call `alfred.provide_review`.
    
    - Set `is_approved=True`.
    - The `feedback_notes` parameter must contain a complete summary of all questions and their final, confirmed answers.
    ```

#### **Acceptance Criteria:**
*   The `planning.yml` persona is updated with the new `greeting` and `communication_style` fields.
*   The `contextualize.md` prompt is updated to include the "Persona Guidelines" section.
*   The `review_context.md` prompt is completely replaced with the new version that instructs the AI on how to manage the "Clarification Loop."

#### **AC Verification:**
*   This will be validated as part of `VT-02` (a new validation run).
*   **Step 1:** Run `plan_task("TS-01")`. Assert that the AI's first message to you is a creative greeting based on the `Alex` persona.
*   **Step 2:** After the AI presents its list of 10 questions, respond with answers to only the first 3.
*   **Assert:** The AI should **not** call `alfred.provide_review`. Instead, it should respond conversationally, acknowledging your answers and then asking for the remaining 7 questions.
*   **Step 3:** Provide the remaining answers.
*   **Assert:** Now that all questions are answered, the AI should finally call `alfred.provide_review` with a complete Q&A summary in the `feedback_notes`.

#### **Unit Tests:**
*   This task is focused on prompt engineering. The validation is primarily observational, as described in the AC Verification. No new automated tests are required, but existing ones must continue to pass.