### **Task Directive: ALFRED-19 - Unify Prompt Generation and Repair the Context Bridge**

**Objective:** To refactor the prompt generation logic so that 100% of prompts are generated by the `PersonaRuntime` using the Jinja2 template system, and to establish a formal context bridge for passing step-specific data from the `Orchestrator` to the `PersonaRuntime`.

#### **1. Refactor `PersonaRuntime.get_current_prompt`**

This method must be enhanced to accept optional, arbitrary context.

**File:** `src/alfred/orchestration/persona_runtime.py`
**Action:** Modify the `get_current_prompt` method signature and logic.

```python
# In PersonaRuntime class...

    def get_current_prompt(
        self, revision_feedback: str | None = None, additional_context: dict | None = None
    ) -> str:
        """
        Generates the prompt for the current state of the persona's HSM,
        now with support for additional, ad-hoc context.
        """
        prompt_template_path = self.config.prompts.get(self.state)

        if not prompt_template_path:
            return f"Error: No prompt template found for state '{self.state}'..."

        template_loader = FileSystemLoader(searchpath=str(settings.packaged_templates_dir))
        jinja_env = Environment(loader=template_loader)
        template = jinja_env.get_template(prompt_template_path)

        # Base context that is always available
        context = {
            "task_id": self.task_id,
            "persona": self.config,
            "revision_feedback": revision_feedback or "No feedback provided.",
            "artifact_content_for_review": json.dumps(self.submitted_artifact_data, indent=2)
            if self.state.endswith("aireview") and self.submitted_artifact_data
            else "",
        }

        # --- NEW: Merge additional context from the orchestrator ---
        if additional_context:
            context.update(additional_context)
        # --- END NEW ---

        return template.render(context)
```

#### **2. Refactor the `Orchestrator` to Delegate Prompt Generation**

The `Orchestrator` will no longer generate any prompt content. It will prepare the context and delegate to the runtime.

**File:** `src/alfred/orchestration/orchestrator.py`
**Action:** Modify the `_update_step_state_and_get_next` method.

```python
# In Orchestrator class...

    def _update_step_state_and_get_next(self, task_id: str, task_state, execution_plan: dict, step_id: str) -> tuple[str, str | None]:
        """Helper method to update step state and get the next prompt via the runtime."""
        runtime = self._get_or_create_runtime(task_id)
        if not runtime:
            return "Error: Could not get runtime.", None

        task_state.completed_steps.append(step_id)
        task_state.current_step += 1
        self._save_task_state(task_state)

        # --- START REFACTOR ---
        steps = execution_plan.get("implementation_steps", [])
        total_steps = len(steps)

        if task_state.current_step >= total_steps:
            # All steps are complete. Transition to the submission state.
            runtime.state = "coding_submission"
            task_state.persona_state = "coding_submission"
            self._save_task_state(task_state)
            message = "All steps complete. Ready for final manifest submission."
            # Get the submission prompt from the runtime, with no extra context.
            next_prompt = runtime.get_current_prompt()
        else:
            # There are more steps. Prepare context for the next step prompt.
            current_step_obj = steps[task_state.current_step]

            # This check is critical. If the step object is just a string, we adapt.
            # This handles the temporary discrepancy until ALFRED-17 is fully complete.
            if isinstance(current_step_obj, dict):
                step_instruction = current_step_obj.get("instruction", "No instruction found.")
                next_step_id = current_step_obj.get("id", f"step_{task_state.current_step}")
            else:
                step_instruction = str(current_step_obj)
                next_step_id = f"step_{task_state.current_step}"

            step_context = {
                "step_id": next_step_id,
                "step_instruction": step_instruction,
                "step_number": task_state.current_step + 1,
                "total_steps": total_steps,
            }
            message = f"Step '{step_id}' complete."
            # Delegate prompt generation to the runtime, passing the step-specific context.
            next_prompt = runtime.get_current_prompt(additional_context=step_context)

        return message, next_prompt
        # --- END REFACTOR ---
```

**File:** `src/alfred/orchestration/orchestrator.py`
**Action:** Modify the initial prompt generation in `begin_task` to also provide step context.

```python
# In Orchestrator class, begin_task method...

    def begin_task(self, task_id: str) -> tuple[str, str | None]:
        # ... setup logging and get runtime ...

        # --- NEW: Provide initial step context if starting a stepwise persona ---
        additional_context = None
        if runtime.config.execution_mode == 'stepwise':
            task_state = self._load_state().tasks.get(task_id)
            if task_state and task_state.execution_plan:
                steps = task_state.execution_plan.get("implementation_steps", [])
                if task_state.current_step < len(steps):
                    current_step_obj = steps[task_state.current_step]
                    if isinstance(current_step_obj, dict):
                        step_instruction = current_step_obj.get("instruction", "N/A")
                        step_id = current_step_obj.get("id", "N/A")
                    else:
                        step_instruction = str(current_step_obj)
                        step_id = f"step_{task_state.current_step}"

                    additional_context = {
                        "step_id": step_id,
                        "step_instruction": step_instruction,
                        "step_number": task_state.current_step + 1,
                        "total_steps": len(steps),
                    }
        # --- END NEW ---

        message = f"Resuming task {task_id}..."
        prompt = runtime.get_current_prompt(additional_context=additional_context)
        return (message, prompt)
```

### **Conclusion**

By implementing this directive, we restore architectural integrity.

*   The `Orchestrator` is now solely responsible for state and context management.
*   The `PersonaRuntime` is now solely responsible for prompt generation via its template system.
*   The context bridge is established via the `additional_context` parameter.
*   All prompts, including the initial one and every subsequent step, will be generated consistently through the same template-based mechanism.

The AI's analysis was a gift. It forced us to identify and eliminate a fundamental design flaw. Execute this correction. The system will be stronger for it.

</architectural_analysis>
