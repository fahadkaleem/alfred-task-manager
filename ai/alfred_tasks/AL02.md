### **Implementation Directive: AL-02 - Implement Two-Step Quality Gate**

**Objective:** To enforce quality, the single review state will be replaced by a mandatory, non-circumventable two-step review process (`AWAITING_AI_REVIEW` -> `AWAITING_HUMAN_REVIEW`) built into the `BaseWorkflowTool`. Autonomous mode will be introduced as the sole mechanism for bypassing the human gate.

**Executor's Action:** Replace the specified files with the provided code.

#### **1. Replace `src/alfred/core/workflow.py`:**
This implements the new review state logic at the base class level.

```python
# src/alfred/core/workflow.py
from enum import Enum
from typing import Any, Dict, List, Type

from pydantic import BaseModel
from transitions.core import Machine

from src.alfred.constants import ToolName, Triggers
from src.alfred.models.planning_artifacts import (
    ContextAnalysisArtifact,
    DesignArtifact,
    ExecutionPlanArtifact,
    StrategyArtifact,
)


class ReviewState(str, Enum):
    """Generic review states applicable to all tools."""

    AWAITING_AI_REVIEW = "awaiting_ai_review"
    AWAITING_HUMAN_REVIEW = "awaiting_human_review"


class PlanTaskState(str, Enum):
    """Working states for the PlanTaskTool's internal State Machine."""

    CONTEXTUALIZE = "contextualize"
    STRATEGIZE = "strategize"
    DESIGN = "design"
    GENERATE_SUBTASKS = "generate_subtasks"
    VERIFIED = "verified"


class BaseWorkflowTool:
    """A base class providing shared State Machine logic for Alfred's tools."""

    def __init__(self, task_id: str, tool_name: str, persona_name: str):
        self.task_id = task_id
        self.tool_name = tool_name
        self.persona_name = persona_name
        self.state: Optional[str] = None
        self.machine: Optional[Machine] = None
        self.artifact_map: Dict[Enum, Type[BaseModel]] = {}
        self.context_store: Dict[str, Any] = {}

    @property
    def is_terminal(self) -> bool:
        """Checks if the current state is a terminal (final) state."""
        return self.state == "verified"

    def _create_review_transitions(
        self, source_state: Enum, success_destination_state: Enum
    ) -> List[Dict[str, Any]]:
        """Factory for the mandatory two-step (AI -> Human) review transitions."""
        return [
            {
                "trigger": Triggers.submit_trigger(source_state.value),
                "source": source_state.value,
                "dest": ReviewState.AWAITING_AI_REVIEW.value,
            },
            {
                "trigger": "ai_approve",
                "source": ReviewState.AWAITING_AI_REVIEW.value,
                "dest": ReviewState.AWAITING_HUMAN_REVIEW.value,
            },
            {
                "trigger": "request_revision",
                "source": ReviewState.AWAITING_AI_REVIEW.value,
                "dest": source_state.value,
            },
            {
                "trigger": "human_approve",
                "source": ReviewState.AWAITING_HUMAN_REVIEW.value,
                "dest": success_destination_state.value,
            },
            {
                "trigger": "request_revision",
                "source": ReviewState.AWAITING_HUMAN_REVIEW.value,
                "dest": source_state.value,
            },
        ]


class PlanTaskTool(BaseWorkflowTool):
    """Encapsulates the state and logic for the `plan_task` command."""

    def __init__(self, task_id: str, persona_name: str = "planning"):
        super().__init__(
            task_id, tool_name=ToolName.PLAN_TASK, persona_name=persona_name
        )

        self.artifact_map = {
            PlanTaskState.CONTEXTUALIZE: ContextAnalysisArtifact,
            PlanTaskState.STRATEGIZE: StrategyArtifact,
            PlanTaskState.DESIGN: DesignArtifact,
            PlanTaskState.GENERATE_SUBTASKS: ExecutionPlanArtifact,
        }

        states = [state.value for state in PlanTaskState] + [
            state.value for state in ReviewState
        ]

        transitions = [
            *self._create_review_transitions(
                PlanTaskState.CONTEXTUALIZE, PlanTaskState.STRATEGIZE
            ),
            *self._create_review_transitions(
                PlanTaskState.STRATEGIZE, PlanTaskState.DESIGN
            ),
            *self._create_review_transitions(
                PlanTaskState.DESIGN, PlanTaskState.GENERATE_SUBTASKS
            ),
            *self._create_review_transitions(
                PlanTaskState.GENERATE_SUBTASKS, PlanTaskState.VERIFIED
            ),
        ]

        self.machine = Machine(
            model=self,
            states=states,
            transitions=transitions,
            initial=PlanTaskState.CONTEXTUALIZE.value,
        )

```

#### **2. Modify `src/alfred/models/alfred_config.py`:**
Add the `autonomous_mode` flag.

```python
# src/alfred/models/alfred_config.py
"""Configuration models for Alfred."""

from enum import Enum
from pydantic import BaseModel, Field


class TaskProvider(str, Enum):
    """Supported task provider types."""
    JIRA = "jira"
    LINEAR = "linear"
    LOCAL = "local"


class ProviderConfig(BaseModel):
    """Configuration for task providers."""
    task_provider: TaskProvider = Field(default=TaskProvider.LOCAL, description="The task management system to use")


class FeaturesConfig(BaseModel):
    """Feature flags for Alfred."""
    scaffolding_mode: bool = Field(default=False, description="Enable scaffolding mode to generate TODO placeholders before implementation")
    autonomous_mode: bool = Field(default=False, description="Enable autonomous mode to bypass human review steps.")


class AlfredConfig(BaseModel):
    """Main configuration model for Alfred."""
    version: str = Field(default="2.0.0", description="Configuration version")
    providers: ProviderConfig = Field(default_factory=ProviderConfig, description="Task provider configuration")
    features: FeaturesConfig = Field(default_factory=FeaturesConfig)
    model_config = {"validate_assignment": True, "extra": "forbid"}

```

#### **3. Modify `src/alfred/tools/provide_review.py` for New Logic:**
This implements the two-step approval and the autonomous mode bypass. Note: This replaces the version from `AL-01` because it adds new logic. This is the authoritative version.

```python
# src/alfred/tools/provide_review.py
from src.alfred.config.manager import ConfigManager
from src.alfred.config.settings import settings
from src.alfred.core.prompter import prompter
from src.alfred.core.workflow import ReviewState
from src.alfred.lib.logger import cleanup_task_logging, get_logger
from src.alfred.lib.task_utils import load_task
from src.alfred/models.schemas import TaskStatus, ToolResponse
from src.alfred/orchestration.orchestrator import orchestrator
from src.alfred/orchestration.persona_loader import load_persona
from src.alfred/state.manager import state_manager

logger = get_logger(__name__)

def provide_review_impl(task_id: str, is_approved: bool, feedback_notes: str = "") -> ToolResponse:
    """Processes review feedback, advancing the active tool's State Machine."""
    if task_id not in orchestrator.active_tools:
        return ToolResponse(status="error", message=f"No active tool found for task '{task_id}'.")

    active_tool = orchestrator.active_tools[task_id]
    task = load_task(task_id)
    if not task:
        return ToolResponse(status="error", message=f"Task '{task_id}' not found.")

    if not is_approved:
        active_tool.request_revision()
        message = "Revision requested. Returning to previous step."
    else:
        current_state = active_tool.state
        if current_state == ReviewState.AWAITING_AI_REVIEW.value:
            active_tool.ai_approve()
            config_manager = ConfigManager(settings.alfred_dir)
            config = config_manager.load()
            if config.features.autonomous_mode:
                logger.info(f"Autonomous mode enabled. Bypassing human review for task {task_id}.")
                active_tool.human_approve()
                message = "AI review approved. Autonomous mode bypassed human review."
            else:
                message = "AI review approved. Awaiting human review."
        elif current_state == ReviewState.AWAITING_HUMAN_REVIEW.value:
            active_tool.human_approve()
            message = "Human review approved. Proceeding to next step."
        else:
            return ToolResponse(status="error", message=f"Cannot provide review from non-review state '{active_tool.state}'.")

    state_manager.update_tool_state(task_id, active_tool)

    if active_tool.is_terminal:
        final_task_status = TaskStatus.READY_FOR_DEVELOPMENT
        state_manager.update_task_status(task_id, final_task_status)
        state_manager.clear_tool_state(task_id)
        del orchestrator.active_tools[task_id]
        cleanup_task_logging(task_id)
        logger.info(f"Tool '{active_tool.tool_name}' for task {task_id} completed.")
        handoff_message = f"Planning for task {task_id} is complete. Task is now {final_task_status.value}."
        return ToolResponse(status="success", message=message, next_prompt=handoff_message)
    else:
        persona_config = load_persona(active_tool.persona_name)
        additional_context = active_tool.context_store.copy()
        additional_context["feedback_notes"] = feedback_notes
        next_prompt = prompter.generate_prompt(
            task=task,
            tool_name=active_tool.tool_name,
            state=active_tool.state,
            persona_config=persona_config,
            additional_context=additional_context,
        )
        return ToolResponse(status="success", message=message, next_prompt=next_prompt)
```

#### **4. Create Generic Review Prompts:**
Executor's Action: Create the following files with the specified content.

**File:** `src/alfred/templates/prompts/generic/awaiting_ai_review.md`
```markdown
# ROLE: {{ persona.name }}, {{ persona.title }}
# TOOL: `alfred.provide_review`
# TASK: {{ task.task_id }}
# STATE: awaiting_ai_review

I have just submitted the artifact for the `{{ additional_context.last_state | replace("_", " ") | title }}` step. I must now perform a critical self-review to ensure the artifact meets all quality standards before it proceeds to human review.

**My Submitted Artifact:**
```json
{{ additional_context.artifact_content }}
```

---
### **Directive: AI Self-Review**

Critically evaluate the artifact above against the original goal of the step.

**Review Checklist:**
1.  **Completeness:** Does the artifact contain all required fields and information?
2.  **Clarity:** Is the information clear, specific, and unambiguous?
3.  **Correctness:** Does the artifact accurately reflect the work that was required?
4.  **Adherence to Standards:** Does the artifact follow all specified formatting and structural rules?

---
### **Required Action**

Call `alfred.provide_review`.
-   If the artifact is perfect, set `is_approved=True`.
-   If the artifact has any flaws, set `is_approved=False` and provide detailed `feedback_notes` explaining the necessary corrections.
```

**File:** `src/alfred/templates/prompts/generic/awaiting_human_review.md`
```markdown
# ROLE: {{ persona.name }}, {{ persona.title }}
# TOOL: `alfred.provide_review`
# TASK: {{ task.task_id }}
# STATE: awaiting_human_review

My self-review is complete. The artifact for the `{{ additional_context.last_state | replace("_", " ") | title }}` step is now ready for your final approval.

**Artifact for Your Review:**
```json
{{ additional_context.artifact_content }}
```

---
### **Directive: Await Human Approval**

Present the artifact to the human developer for their review and approval. They will provide a simple "yes/no" or "approve/reject" decision.

-   If they approve, call `alfred.provide_review` with `is_approved=True`.
-   If they request changes, call `alfred.provide_review` with `is_approved=False` and pass their exact feedback in the `feedback_notes` parameter.