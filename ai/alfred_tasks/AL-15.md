### **TASK: AL-15 (Revised)**

#### **Title:**
Tool Content: Implement `plan_task` Artifact Models and Validation

#### **Context:**
Our prompt templates instruct the AI to submit structured JSON artifacts. To ensure these artifacts are valid and can be reliably used, we must define them as Pydantic models and integrate validation into our workflow. This task involves creating the specific `*Artifact` models for the `plan_task` lifecycle and enhancing the `submit_work` tool to perform validation against them. This is a critical step to enforce the data contracts defined in our prompts.

#### **Implementation Details:**
1.  **Create a `planning_artifacts.py` module** in `src/alfred/models/`.
2.  **Define Pydantic models for each artifact** generated during the `plan_task` lifecycle.
3.  **Enhance `BaseWorkflowTool`** to include a mapping of states to their required artifact models.
4.  **Refactor `submit_work_impl` to perform validation.** Before persisting the artifact, it will look up the required model for the current state, attempt to validate the submitted JSON, and return a descriptive error to the AI if validation fails.

**Dev Notes:**
*   This makes our system robust. The AI is forced to adhere to the specified structure, or it cannot proceed.
*   The state-to-artifact mapping in the `BaseWorkflowTool` makes the validation logic generic and reusable for all future tools.

**Files to Modify/Create:**

1.  **`src/alfred/models/planning_artifacts.py` (NEW FILE):**
    ```python
    # src/alfred/models/planning_artifacts.py
    from pydantic import BaseModel, Field
    from typing import List, Dict
    from .schemas import SLOT

    class ContextAnalysisArtifact(BaseModel):
        context_summary: str
        affected_files: List[str]
        questions_for_developer: List[str]

    class StrategyArtifact(BaseModel):
        high_level_strategy: str
        key_components: List[str]
        new_dependencies: List[str] = Field(default_factory=list)
        risk_analysis: str | None = None

    class DesignArtifact(BaseModel):
        detailed_design: str
        file_breakdown: List[Dict[str, str]]

    # The Execution Plan is simply a list of SLOTs
    ExecutionPlanArtifact = List[SLOT]
    ```

2.  **`src/alfred/core/workflow.py` (MODIFY):**
    ```python
    # src/alfred/core/workflow.py
    # ... imports ...
    from typing import List, Dict, Any, Type
    from pydantic import BaseModel
    
    class BaseWorkflowTool:
        """..."""
        def __init__(self, ...):
            # ...
            # Add a new attribute for artifact mapping
            self.artifact_map: Dict[Enum, Type[BaseModel]] = {}

    class PlanTaskTool(BaseWorkflowTool):
        """..."""
        def __init__(self, task_id: str, ...):
            super().__init__(...)
            # ...
            # Import the new artifact models
            from src.alfred.models.planning_artifacts import ContextAnalysisArtifact, StrategyArtifact, DesignArtifact, ExecutionPlanArtifact
            
            # Define the artifact validation map for this tool
            self.artifact_map = {
                PlanTaskState.CONTEXTUALIZE: ContextAnalysisArtifact,
                PlanTaskState.STRATEGIZE: StrategyArtifact,
                PlanTaskState.DESIGN: DesignArtifact,
                PlanTaskState.GENERATE_SLOTS: ExecutionPlanArtifact,
            }
            # ... machine setup ...
    ```

3.  **`src/alfred/tools/submit_work.py` (MODIFY `submit_work_impl`):**
    ```python
    # src/alfred/tools/submit_work.py
    # ... imports ...
    from pydantic import ValidationError

    def submit_work_impl(task_id: str, artifact: dict) -> ToolResponse:
        # ... (find active_tool and task as before) ...

        # --- NEW: Artifact Validation ---
        current_state = active_tool.state
        artifact_model = active_tool.artifact_map.get(current_state)

        if artifact_model:
            try:
                # Validate the submitted dictionary against the Pydantic model
                validated_artifact = artifact_model.model_validate(artifact)
                logger.info(f"Artifact for state '{current_state.value}' validated successfully against {artifact_model.__name__}.")
            except ValidationError as e:
                error_msg = f"Artifact validation failed for state '{current_state.value}'. The submitted artifact does not match the required structure.\n\nValidation Errors:\n{e}"
                return ToolResponse(status="error", message=error_msg)
        else:
            validated_artifact = artifact # No validator for this state, proceed
        
        # --- Artifact Persistence ---
        rendered_artifact = f"### Submission for State: `{current_state.value}`\n\n```json\n{json.dumps(artifact, indent=2)}\n```"
        artifact_manager.append_to_scratchpad(task_id, rendered_artifact)
        
        # ... (rest of the function: state transition, prompt generation) ...
    ```

#### **Acceptance Criteria:**
*   The `src/alfred/models/planning_artifacts.py` file exists and contains the specified Pydantic models.
*   The `PlanTaskTool` class defines the `artifact_map` dictionary, linking states to their corresponding artifact models.
*   The `submit_work_impl` function correctly validates incoming artifacts against the models defined in the active tool's `artifact_map`.
*   Submitting an artifact with an incorrect structure to `submit_work` results in a `ToolResponse` with `status: "error"` and a descriptive message containing the Pydantic validation errors.

#### **AC Verification (using "Simulated Reality" harness):**
*   Create a test that:
    1.  Calls `plan_task_impl` to start the tool.
    2.  Calls `submit_work_impl` for the `CONTEXTUALIZE` state with an **invalid** artifact (e.g., missing the `context_summary` field).
    3.  Asserts that the returned `ToolResponse` has `status: "error"` and that the message contains details about the validation failure.
    4.  Calls `submit_work_impl` again with a **valid** `ContextAnalysisArtifact`.
    5.  Asserts that the call succeeds and the state machine transitions correctly.

#### **Unit Tests:**
*   **`tests/models/test_planning_artifacts.py`:** Write simple tests to ensure each new artifact model can be instantiated correctly.
*   **`tests/tools/test_submit_work.py`:** Add the new integration tests described in AC Verification.