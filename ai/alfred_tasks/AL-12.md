### **TASK: AL-12**

#### **Title:**
Core Engine: Implement the `submit_work` Tool

#### **Context:**
The Alfred Command Suite can now initiate tools, but cannot process the work submitted by the AI. This task is to implement the critical `submit_work` tool. This tool acts as the generic "inbox" for all work artifacts generated by the AI agent. Its sole responsibility is to receive an artifact, persist it for human review, and advance the internal State Machine of the currently active tool to its corresponding review state. This is the first half of the engine that drives our conversational workflows.

#### **CRITICAL: REUSE EXISTING COMPONENTS**
This implementation must reuse the `Orchestrator`, `ArtifactManager`, `Prompter`, `Task` model, and `BaseWorkflowTool` as they exist in the current codebase. We are building on our foundation, not replacing it.

#### **Implementation Details:**
1.  **Create the `submit_work.py` module.** This will house the implementation logic.
2.  **Implement the `submit_work_impl` function.** This function will be the engine for this tool.
3.  **Integrate with `ArtifactManager` for persistence.** The submitted artifact must be written to the task's `scratchpad.md`. We will reuse the `artifact_manager.append_to_scratchpad` method.
4.  **Integrate with `Orchestrator` for state lookup.** The function must get the currently active tool for the `task_id` from `orchestrator.active_tools`.
5.  **Implement generic State Machine triggering.** The function must dynamically construct the trigger name (e.g., `submit_contextualize`) from the tool's current state and call it on the `machine` object.
6.  **Integrate with `Prompter` for the response.** After a successful state transition, the function must use the `prompter` to generate the prompt for the *new* review state.

**Dev Notes:**
*   Error handling is paramount. The function must gracefully handle the case where no active tool is found for a given `task_id`.
*   To make this tool generic, the `BaseWorkflowTool` must have `tool_name` and `persona_name` attributes that can be accessed by `submit_work_impl`. The code provided in the diff for `workflow.py` already includes this, which is correct.

**Files to Create/Modify:**

1.  **`src/alfred/tools/submit_work.py` (CREATE OR REPLACE):**
    ```python
    # src/alfred/tools/submit_work.py
    import json
    from src.alfred.models.schemas import ToolResponse, Task
    from src.alfred.orchestration.orchestrator import orchestrator
    from src.alfred.lib.task_utils import load_task
    from src.alfred.lib.artifact_manager import artifact_manager
    from src.alfred.core.prompter import prompter
    from src.alfred.lib.persona_loader import load_persona
    from src.alfred.lib.logger import get_logger

    logger = get_logger(__name__)

    def submit_work_impl(task_id: str, artifact: dict) -> ToolResponse:
        """
        Implements the logic for submitting a work artifact to the active tool.
        """
        if task_id not in orchestrator.active_tools:
            return ToolResponse(status="error", message=f"No active tool found for task '{task_id}'. Cannot submit work.")
        
        active_tool = orchestrator.active_tools[task_id]
        task = load_task(task_id)
        if not task:
            return ToolResponse(status="error", message=f"Task '{task_id}' not found.")

        # --- Artifact Persistence ---
        # Reuse the existing ArtifactManager to append to the human-readable scratchpad.
        # We create a simple, clean representation of the submitted artifact.
        rendered_artifact = f"### Submission for State: `{active_tool.state}`\n\n```json\n{json.dumps(artifact, indent=2)}\n```"
        artifact_manager.append_to_scratchpad(task_id, rendered_artifact)
        
        # --- State Transition ---
        current_state_val = active_tool.state.value if hasattr(active_tool.state, 'value') else active_tool.state
        trigger = f"submit_{current_state_val}"
        
        if not hasattr(active_tool, trigger):
            return ToolResponse(status="error", message=f"Invalid action: cannot submit from state '{current_state_val}'. No trigger '{trigger}' exists.")
        
        # Trigger the state transition (e.g., tool.submit_contextualize())
        getattr(active_tool, trigger)()
        logger.info(f"Task {task_id}: State transitioned via trigger '{trigger}' to '{active_tool.state}'.")
        
        # --- Generate Next Prompt for the new review state ---
        try:
            persona_config = load_persona(active_tool.persona_name)
        except FileNotFoundError as e:
            return ToolResponse(status="error", message=str(e))
            
        next_prompt = prompter.generate_prompt(
            task=task,
            tool_name=active_tool.tool_name,
            state=active_tool.state,
            persona_config=persona_config,
            # Pass the submitted artifact into the context for the AI review prompt
            additional_context={"artifact_content": json.dumps(artifact, indent=2)}
        )

        return ToolResponse(status="success", message="Work submitted. Awaiting review.", next_prompt=next_prompt)
    ```

#### **Acceptance Criteria:**
*   A user can successfully call the `plan_task` tool to start a planning session.
*   The AI agent can then successfully call the `submit_work` tool with a valid artifact.
*   The `PlanTaskTool` instance's internal state correctly transitions from a `_working` state (e.g., `CONTEXTUALIZE`) to a `_review` state (e.g., `REVIEW_CONTEXT`).
*   The submitted artifact is correctly appended to the `scratchpad.md` file for the task.
*   A new prompt, corresponding to the `_review` state, is generated and returned.

#### **AC Verification (using "Simulated Reality" harness):**
*   Create a test that performs the following sequence:
    1.  Use `alfred_test_project` to set up a `task.json`, `planning.yml` persona, and prompt templates for `contextualize` and `review_context`.
    2.  Call `plan_task_impl("TS-01")`.
    3.  Call `submit_work_impl("TS-01", artifact={"context_summary": "..."})`.
    4.  Assert that the `ToolResponse` is successful and the `next_prompt` corresponds to the `review_context` template.
    5.  Check the `orchestrator.active_tools` and assert that the state of the `PlanTaskTool` instance for `TS-01` is now `REVIEW_CONTEXT`.
    6.  Read the `scratchpad.md` file from the test directory and assert that it contains the JSON artifact.

#### **Unit Tests:**
*   Create a new test file `tests/tools/test_submit_work.py`.
*   Write a single, comprehensive integration test `test_submit_work_advances_state` that follows the AC Verification steps using the `alfred_test_project` fixture.
*   Write a test `test_submit_work_fails_if_no_active_tool` to validate the error handling.
