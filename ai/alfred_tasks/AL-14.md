### **TASK: AL-14 (Revised)**

#### **Title:**
Tool Content: Implement `plan_task` Prompt Templates

#### **Context:**
The `plan_task` tool's engine and State Machine are complete. We must now provide the "content" for the conversation by creating the prompt templates for each of its internal states. Each template will follow our standardized format and will contain the specific directives and required artifact structures for that stage of planning. This task will bring the `plan_task` conversation to life.

#### **Implementation Details:**
1.  **Create the `plan_task` directory** inside `src/alfred/templates/prompts/`.
2.  **Create one `.md` template file for each state** defined in the `PlanTaskState` Enum. The content of each file must be exactly as specified below. These templates are the core of our user experience and must be implemented with precision.

**Dev Notes:**
*   Each `_working` state template (`contextualize`, `strategize`, etc.) defines the precise JSON structure for the artifact the AI is required to submit. This is a hard contract.
*   Each `_review` state template instructs the AI to perform a self-critique based on specific criteria before prompting the human.
*   All templates use the Jinja2 variables (`{{ task.title }}`, `{{ persona.name }}`, etc.) to inject context.

**Files to Create:**

1.  **`src/alfred/templates/prompts/plan_task/contextualize.md` (NEW FILE):**
    ```markdown
    # ROLE: {{ persona.name }}, {{ persona.title }}
    # TOOL: `alfred.plan_task`
    # TASK: {{ task.task_id }}
    # STATE: contextualize

    I am beginning the planning process for '{{ task.title }}'.

    **Task Context:**
    - **Goal:** {{ task.context }}
    - **Implementation Overview:** {{ task.implementation_details }}
    - **Acceptance Criteria:**
    {% for criterion in task.acceptance_criteria %}
      - {{ criterion }}
    {% endfor %}

    ---
    ### **Directive: Codebase Analysis & Ambiguity Detection**

    Your mission is to become the expert on this task. You must:
    1.  **Analyze the existing codebase.** Start from the project root. Identify all files and code blocks relevant to the provided Task Context.
    2.  **Identify Ambiguities.** Compare the task goal with your code analysis. Create a list of precise questions for the human developer to resolve any uncertainties or missing requirements.

    ---
    ### **Required Action**

    You MUST now call `alfred.submit_work` with a `ContextAnalysisArtifact`.

    **Required Artifact Structure:**
    ```json
    {
      "context_summary": "string - A summary of your understanding of the existing code and how the new feature will integrate.",
      "affected_files": ["string - A list of files you have identified as relevant."],
      "questions_for_developer": ["string - Your list of precise questions for the human developer."]
    }
    ```
    ```

2.  **`src/alfred/templates/prompts/plan_task/review_context.md` (NEW FILE):**
    ```markdown
    # ROLE: {{ persona.name }}, {{ persona.title }}
    # TOOL: `alfred.plan_task`
    # TASK: {{ task.task_id }}
    # STATE: review_context

    My initial analysis has generated the following questions. I must now clarify these with the human developer to ensure my understanding is complete before proceeding with the technical strategy.

    ---
    ### **Directive: User Clarification**

    Present these questions to the human developer and await their answers.

    **My Questions:**
    {% set artifact = artifact_content | fromjson %}
    {% for question in artifact.questions_for_developer %}
    - {{ question }}
    {% endfor %}

    ---
    ### **Required Action**

    Once you have the developer's answers, you MUST call `alfred.provide_review` with `is_approved=True` and include the developer's answers in the `feedback_notes`. Format the notes as a clear Q&A string.
    
    If the developer rejects the context and wants you to re-analyze, call `provide_review` with `is_approved=False`.
    ```

3.  **Create stub files for the remaining states:** `strategize.md`, `review_strategy.md`, `design.md`, `review_design.md`, `generate_slots.md`, `review_plan.md`, `verified.md`. The content will be fully specified in a subsequent task. This ensures the prompter does not fail.
    *   Example for `strategize.md`: `# ROLE: {{ persona.name }}... etc. TODO: Implement full prompt.`

#### **Acceptance Criteria:**
*   A directory `src/alfred/templates/prompts/plan_task/` exists.
*   It contains `.md` files for all states in the `PlanTaskState` enum.
*   The `contextualize.md` and `review_context.md` files contain the exact content specified.
*   The other files exist as placeholders.

#### **AC Verification:**
*   This will be verified during the integration test in `AL-16`. Manually inspect the file system to ensure the files are created correctly.

#### **Unit Tests:**
*   No new tests are required for this content-creation task. Existing `Prompter` tests will validate that these templates can be loaded.